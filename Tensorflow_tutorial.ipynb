{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZTxl6CL0jLM62WetMV6G9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamByte/Machine-Learning/blob/main/Tensorflow_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wKFEb5aNRmvV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "a = tf.constant(4)\n",
        "b = tf.constant(5)\n",
        "c = a+b\n",
        "\n",
        "# no requirement to run session in tensorflow 2.0 and above. now eager mode is default\n",
        "# sess = tf.Session()\n",
        "# sess.run(c)\n",
        "\n",
        "print(c.numpy())\n",
        "\n",
        "a = tf.constant([[4,2]])\n",
        "b = tf.constant([[1],[3]])\n",
        "\n",
        "res = tf.matmul(a,b)\n",
        "print(res.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSXcSUu2Sqe9",
        "outputId": "f7a026c5-2028-4b2b-a8aa-cd620f1b15f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "[[10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to use session and placeholder now, use in this way..\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# a = tf.constant(4)\n",
        "# b = tf.constant(5)\n",
        "# c = a + b\n",
        "\n",
        "# with tf.compat.v1.Session() as sess:\n",
        "#   print(sess.run(c))\n"
      ],
      "metadata": {
        "id": "BX55WDF0bYub"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "\n",
        "a = tf.Variable(10)\n",
        "print(a.numpy())\n",
        "\n",
        "a.assign(20)\n",
        "a.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sisNeX1ncfXF",
        "outputId": "470f14c2-dd25-4f1e-b0ed-8a2ea8608da2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST DATASET MODEL"
      ],
      "metadata": {
        "id": "l3r_uteRmYBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dfroVs1h9Vgx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "(x_train, y_train), (x_test, y_test)= keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train.shape, y_train.shape, x_train.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fgg7rV_hhRa",
        "outputId": "0c8531ec-5dee-4cdd-e617-b36d26796b27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), dtype('uint8'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the input data\n",
        "x_train = tf.reshape(x_train,[-1,784])\n",
        "x_test = tf.reshape(x_test,[-1,784])\n",
        "\n",
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enixsyp_LfWP",
        "outputId": "8c06df4a-bcf2-4412-ef0d-a269201402a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([60000, 784]), TensorShape([10000, 784]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping output data to one hot vector\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN2PKpn_ssgJ",
        "outputId": "0a4f261e-bf3e-47cb-904f-427b983666f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing data to tf.float32 since all the weights and biases are in tf.float2\n",
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "y_test = tf.cast(y_test, tf.float32)"
      ],
      "metadata": {
        "id": "E5sOJE2pNfJP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing one sample image\n",
        "\n",
        "sample_img = tf.reshape(x_train[550],[28,28]) \n",
        "\n",
        "# from array of unit8 type to numpy array of float type\n",
        "sample_img = np.array(sample_img, dtype = 'float')\n",
        "\n",
        "print(sample_img.dtype)\n",
        "plt.imshow(sample_img,cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FdQY9Yr4r3xk",
        "outputId": "5bd9b877-beaf-420a-9bb7-9e1861a09bb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of neural network\n",
        "\n",
        "# nodes\n",
        "n_input = 784\n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 256\n",
        "n_output = 10\n",
        "\n",
        "# weights and  biases\n",
        "\n",
        "weights = {\n",
        "    'h1' : tf.Variable(tf.random.normal([n_input,n_hidden1])),\n",
        "    'h2' : tf.Variable(tf.random.normal([n_hidden1,n_hidden2])),\n",
        "    'out' : tf.Variable(tf.random.normal([n_hidden2,n_output]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'h1' : tf.Variable(tf.random.normal([n_hidden1])),\n",
        "    'h2' : tf.Variable(tf.random.normal([n_hidden2])),\n",
        "    'out' : tf.Variable(tf.random.normal([n_output]))\n",
        "}\n",
        "\n",
        "# 'h1' : tf.Variable(tf.random.normal([n_input,n_hidden1]), trainable= False) can be used if we don't want any variable to get trained. default is true"
      ],
      "metadata": {
        "id": "cJsZA4-Gr6HT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights['h1'].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH8_6ClhCUeW",
        "outputId": "9ee54071-4da2-4fb2-b866-eea049f0d1c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward propogation\n",
        "\n",
        "def forward_propogation(x,weights,biases):\n",
        "\n",
        "  in_layer1 = tf.matmul(x,weights['h1']) + biases['h1']\n",
        "  out_layer1 = tf.nn.relu(in_layer1)\n",
        "\n",
        "  in_layer2 = tf.matmul(out_layer1,weights['h2']) + biases['h2']\n",
        "  out_layer2 = tf.nn.relu(in_layer2)\n",
        "\n",
        "  output = tf.matmul(out_layer2,weights['out']) + biases['out']\n",
        "\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "lCwBh0RO32ro"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "these steps are testing what happens when we forward prpogate our data with random weights. Accuracy should be around 10% for 10 classes. After training the model, we can rerun it to check accuracy again."
      ],
      "metadata": {
        "id": "6mBVqyS3PL1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions without training the model\n",
        "x = x_train\n",
        "y = y_train\n",
        "\n",
        "pred = forward_propogation(x,weights,biases)\n"
      ],
      "metadata": {
        "id": "EdhnAsUw8IKB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss / Cost\n",
        "# first logits calculated on prediction -> softmax -> cross entropy\n",
        "\n",
        "loss = tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y) # gives an array\n",
        "loss.numpy(), loss.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoNHfT9RK9RR",
        "outputId": "5c3d2f52-6887-4be9-806d-709029d5f5ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([581331.56,      0.  , 637413.9 , ..., 642419.75, 675667.7 ,\n",
              "        343129.16], dtype=float32), TensorShape([60000]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.reduce_mean(loss)   # taking mean of the array/ can do sum also\n",
        "loss.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1SSKpCIOCmr",
        "outputId": "8efe9acc-85bb-4a05-af3a-6ad256d5a8c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "387447.34"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "predictions = tf.argmax(pred,axis = 1)\n",
        "true_labels = tf.argmax(y,axis = 1)\n",
        "correct_pred = tf.equal(predictions, true_labels)\n",
        "\n",
        "# predictions, true_labels, correct_pred\n",
        "result = tf.reduce_sum(tf.cast(correct_pred, tf.int32))\n",
        "result.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1fzolSlJovf",
        "outputId": "a51d333f-7b47-4513-be29-7358f1728585"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4201"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "steps without training over. (non essential steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xCt2lbHPenj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training our model"
      ],
      "metadata": {
        "id": "q1CijSRoP9XW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss should be calculated inside the tf.GradientTape() context, as the purpose of the tf.GradientTape is to record the forward pass operations for the purpose of computing gradients for optimization. The loss function provides a scalar value indicating the degree of difference between the predictions and actual labels, which is then used to update the model parameters during optimization. If the loss calculation is performed outside the tf.GradientTape context, the gradients cannot be computed and the optimization step cannot be performed."
      ],
      "metadata": {
        "id": "FPjML1XgTRIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "learnable_variables = [weights['h1'], weights['h2'], weights['out'], biases['h1'], biases['h2'], biases['out']]\n",
        "\n",
        "# Total number of samples\n",
        "total_samples = x_train.shape[0]\n",
        "\n",
        "# Total number of iterations (steps) per epoch\n",
        "steps_per_epoch = total_samples // batch_size      # floor divison\n",
        "\n",
        "# choosing our optimizer\n",
        "optimizer = tf.optimizers.Adam(learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    total_cost = 0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Get the current batch of data\n",
        "        start = step * batch_size\n",
        "        end = start + batch_size\n",
        "        x_batch = x_train[start:end]\n",
        "        y_batch = y_train[start:end]\n",
        "        \n",
        "        # Use tf.GradientTape to record operations\n",
        "        with tf.GradientTape() as tape:\n",
        "          \n",
        "            # Perform forward propagation on the batch of data\n",
        "            pred = forward_propogation(x_batch, weights, biases)\n",
        "            # Calculate the loss\n",
        "            current_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_batch))\n",
        "\n",
        "        # Use the recorded operations to compute gradients\n",
        "        grads = tape.gradient(current_loss, learnable_variables)\n",
        "        \n",
        "        # Apply gradients to update weights and biases\n",
        "        optimizer.apply_gradients(zip(grads, learnable_variables))\n",
        "\n",
        "        total_cost += current_loss\n",
        "        \n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {total_cost}\")\n"
      ],
      "metadata": {
        "id": "eebrgNKOPJzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2642f9fb-dfb3-4b21-c51f-03a21248a379"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 3256648.0\n",
            "Epoch: 1, Loss: 1902696.125\n",
            "Epoch: 2, Loss: 1352318.375\n",
            "Epoch: 3, Loss: 1021604.625\n",
            "Epoch: 4, Loss: 798880.375\n",
            "Epoch: 5, Loss: 635129.875\n",
            "Epoch: 6, Loss: 515793.375\n",
            "Epoch: 7, Loss: 416371.40625\n",
            "Epoch: 8, Loss: 341649.21875\n",
            "Epoch: 9, Loss: 276058.5625\n",
            "Epoch: 10, Loss: 226665.65625\n",
            "Epoch: 11, Loss: 183744.59375\n",
            "Epoch: 12, Loss: 154888.265625\n",
            "Epoch: 13, Loss: 123744.0390625\n",
            "Epoch: 14, Loss: 103769.3125\n",
            "Epoch: 15, Loss: 82748.109375\n",
            "Epoch: 16, Loss: 68137.4453125\n",
            "Epoch: 17, Loss: 50423.03515625\n",
            "Epoch: 18, Loss: 42729.00390625\n",
            "Epoch: 19, Loss: 35206.75390625\n",
            "Epoch: 20, Loss: 30330.28125\n",
            "Epoch: 21, Loss: 23250.84765625\n",
            "Epoch: 22, Loss: 18944.943359375\n",
            "Epoch: 23, Loss: 16182.892578125\n",
            "Epoch: 24, Loss: 16711.6796875\n",
            "Epoch: 25, Loss: 11344.3896484375\n",
            "Epoch: 26, Loss: 11062.0537109375\n",
            "Epoch: 27, Loss: 10990.7333984375\n",
            "Epoch: 28, Loss: 11327.52734375\n",
            "Epoch: 29, Loss: 10902.8681640625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_test\n",
        "y = y_test\n",
        "pred = forward_propogation(x,weights,biases)\n",
        "\n",
        "# accuracy\n",
        "predictions = tf.argmax(pred,axis = 1)\n",
        "true_labels = tf.argmax(y,axis = 1)\n",
        "correct_pred = tf.equal(predictions, true_labels)\n",
        "\n",
        "result = tf.reduce_sum(tf.cast(correct_pred, tf.int32))\n",
        "percentage = (result/len(x))*100\n",
        "print(f'Accuracy is {percentage} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXSbQCiYb0i4",
        "outputId": "1323ce4e-77c0-4c2c-8522-85f9df29f822"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 94.57 %\n"
          ]
        }
      ]
    }
  ]
}